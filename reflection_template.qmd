---
title: "STAT 331 Portfolio"
author: "Jennifer Ibarra"
format: html
code-overflow: scroll
embed-resources: true
layout: margin-left
editor: visual
execute: 
  eval: false 
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an D.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv` Example 1

```{r}
#| label: wd-1-csv-1

surveys <- read_csv("surveys.csv")

install.packages("gitcreds")
gitcreds::gitcreds_set(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)


#lab 2 Q1

```

-   `csv` Example 2

```{r}
#| label: wd-1-csv-2

surveys <- read_csv(here("Week 2", "Lab 2", "surveys.csv"))

#the original code from lab 9 had here::here() but since we would have the here package loaded we wouldn't need that.


```

-   `xlsx`

```{r}
#| label: wd-1-xlsx

library(readxl)
military <- read_xlsx("gov_spending_per_capita.xlsx",
                      sheet = ,
                      skip  = ,
                      n_max = ,
                      na = c()
                      )

#PA4 Question 1, so why do we even hav sheet, skip, n_max, or na = c()? These options allow us to naviagate an excel sheet with multiple subsheets, header rows that aren't data, how many rows to read, and how to interpret NAs in our file.



```

**WD-2: I can select necessary columns from a dataset.**

-   Example selecting specified columns

```{r}
#| label: wd-2-ex-1
#Growing comment: Selecting columns based on their names doesn't require quotes!

#Got rid of the quotes in the 
#Lab 3 Question 5

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants > 10) |>
  mutate(teacher_id = as.character(teacher_id),
         question_no = as.character(question_no)) |>
  select(course_id, teacher_id, question_no, no_participants,  resp_share, SET_score_avg, percent_failed_cur, academic_degree, seniority, sex) #all this

#CHECK ON MIDTERM EVAL

glimpse(teacher_evals_clean)
```

-   Example removing specified columns

```{r}
#| label: wd-2-ex-2

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants > 10) |>
  mutate(teacher_id = as.character(teacher_id),
         question_no = as.character(question_no)) |>
  select(-stud_grade_avg:-stud_grade_var_coef, 
         -stud_grade_avg_cur:-maximum_score)

#alright so what if we just not selected the other columns? Ta-dah


```

-   Example selecting columns based on logical values (e.g., `starts_with()`, `ends_with()`, `contains()`, `where()`)

```{r}
#| label: wd-2-ex-3

#lab 4

childcare_long <- ca_childcare |>
  pivot_longer(cols = starts_with("mc_"), #here
    names_to = "age_group",
    names_prefix = "mc_",
    values_to = "weekly_price")

#CHECK ON MIDTERM EVAL

```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   Numeric Example 1

```{r}
#| label: wd-3-numeric-ex-0

median_household <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |> #right here
  group_by(census_region, study_year) |>
  summarise(median_income = median(mhi_2018, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = study_year, values_from = median_income) |>
  arrange(desc("2018"))

```

-   Numeric Example 2

```{r}
#| label: wd-3-numeric-ex-1

teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants > 10) |> #right here
  mutate(teacher_id = as.character(teacher_id),
         question_no = as.character(question_no)) |>
  select("course_id", "teacher_id", "question_no", "no_participants", "resp_share", "SET_score_avg", "percent_failed_cur", "academic_degree", "seniority", "sex")

#need to find another example of this

```

-   Character Example 1 (any context)

```{r}
#| label: wd-3-character

witness1 <- person |>
  filter(str_detect(address_street_name, regex("Northwestern Dr", ignore_case = TRUE))) |> 
  filter(address_number == max(address_number))

witness2 <- person |>
  filter(str_detect(address_street_name, regex("Franklin Ave", ignore_case = TRUE))) |> 
  filter(str_detect(name, "Annabel"))

witnesses <- bind_rows(witness1, witness2)

```

-   Character Example 2 (example must use functions from **stringr**)

```{r}
#| label: wd-3-string

get_fit_member_suspects <- get_fit_now_member |>
  filter(str_detect(id, regex("^48Z", ignore_case = TRUE)))


get_fit_check_suspects <- get_fit_now_check_in |>
  filter(str_detect(membership_id, regex("^48Z", ignore_case = TRUE))) |>
  filter(check_in_date == 20180109)

suspects_combined <- get_fit_check_suspects |>
  inner_join(get_fit_member_suspects, by = c("membership_id" = "id"))

```

-   Date (example must use functions from **lubridate**)

```{r}
#| label: wd-3-date

sql_symphony_attendees <- facebook_event_checkin |>
 filter(str_detect(event_name, regex("SQL Symphony Concert", ignore_case = TRUE)),
   lubridate::year(date) == 2017,
   lubridate::month(date) == 12)

```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   Numeric Example 1

```{r}
#| label: wd-4-numeric-ex-1

#lab 3 question 1

sen_vs_jun <- teacher_evals |>
  filter(question_no == 903) |>
  mutate(
    SET_level = if_else(SET_score_avg >= 4, "excellent", "standard"),
    sen_level = if_else(seniority <= 4, "junior", "senior")
  ) |>
  select(course_id, SET_level, sen_level) 

```

-   Numeric Example 2

```{r}
#| label: wd-4-numeric-ex-2

```

-   Factor Example 1 (renaming levels)

```{r}
#| label: wd-4-factor-ex-1

#lab 4 question 7

childcare_long <- ca_childcare |>
  pivot_longer(cols = starts_with("mc_"),  
    names_to = "age_group",
    names_prefix = "mc_",
    values_to = "weekly_price")

childcare_long <- childcare_long |>
  mutate(census_region = fct_reorder(census_region, weekly_price, .fun = median, na.rm = TRUE),
    age_group = str_to_title(age_group))

#need to alter this and add a relevel for the infant, toddler, and preschooler name.

```

-   Factor Example 2 (reordering levels)

```{r}
#| label: wd-4-factor-ex-2

childcare_long <- childcare_long |>
  mutate(census_region = fct_reorder(census_region, weekly_price, .fun = median, na.rm = TRUE),
    age_group = str_to_title(age_group))

```

-   Character (example must use functions from **stringr**)

```{r}
#| label: wd-4-string

#lab 4 question 4

ca_childcare <- ca_childcare |> 
  mutate(county_name = str_remove(county_name, " County")) |> #here
  mutate(census_region = fct_collapse(county_name,
    "Superior California" = superior_counties,
    "North Coast" = north_coast_counties,
    "San Francisco Bay Area" = san_fran_counties,
    "Northern San Joaquin Valley" = n_san_joaquin_counties,
    "Central Coast" = central_coast_counties,
    "Southern San Joaquin Valley" = s_san_joaquin_counties,
    "Inland Empire" = inland_counties,
    "Los Angeles" = la_county,
    "Orange" = orange_county,
    "San Diego/Imperial" = san_diego_imperial_counties))

```

-   Date (example must use functions from **lubridate**)

```{r}
#| label: wd-4-date

sql_symphony_attendees <- facebook_event_checkin |>
 filter(str_detect(event_name, regex("SQL Symphony Concert", ignore_case = TRUE)), year(date) == 2017, month(date) == 12)

```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()` Example 1

```{r}
#| label: wd-5-left-ex-1

ca_childcare <- childcare_costs |> 
                left_join(x = childcare_costs,
                          y = counties,
                          by = join_by(county_fips_code == county_fips_code)) |>
                filter(state_name == "California")

```

-   `right_join()` Example 1

```{r}
#| label: wd-5-right

witness1 <- person |>
  filter(str_detect(address_street_name, regex("Northwestern Dr", ignore_case = TRUE))) |> 
  filter(address_number == max(address_number))

witness2 <- person |>
  filter(str_detect(address_street_name, regex("Franklin Ave", ignore_case = TRUE))) |> 
  filter(str_detect(name, "Annabel"))

witnesses <- bind_rows(witness1, witness)

#so this worked but we can add a right join here for fun by just

witness_join <- right_join(person, witnesses, by ="person_id")

#now it is in one dataframe

```

-   `left_join()` **or** `right_join()` Example 2

```{r}
#| label: wd-5-left-right-ex-2

ca_childcare <- ca_childcare |>
              left_join ( x = ca_childcare,
                          y = tax_rev_clean,
                          by = join_by(county_name == entity_name)) |>
              group_by(county_name)

```

-   `inner_join()` Example 1

```{r}
#| label: wd-5-inner-ex-1

witnesses <- witnesses |>
  inner_join(interview, by = c("id" = "person_id"))
```

-   `inner_join()` Example 2

```{r}
#| label: wd-5-inner-ex-2

suspects_combined <- get_fit_check_suspects |>
  inner_join(get_fit_member_suspects, by = c("membership_id" = "id"))

```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r}
#| label: wd-6-semi

#suspect list not joining the interview data with suspect but filtering the interview data set 

#semi joins are only looking for matches

```

-   `anti_join()`

```{r}
#| label: wd-6-anti

```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r}
#| label: wd-7-long

childcare_long <- ca_childcare |>
  pivot_longer(cols = starts_with("mc_"),  
    names_to = "age_group",
    names_prefix = "mc_",
    values_to = "weekly_price")

```

-   `pivot_wider()`

```{r}
#| label: wd-7-wide

median_household <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(census_region, study_year) |>
  summarise(median_income = median(mhi_2018, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = study_year, values_from = median_income) |>
  arrange(desc("2018"))


```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

The following assignments satisfy the above criteria:

-   Example 1
-   Example 2
-   Example 3
-   Example 4
-   Example 5

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

```{r}
#| label: r-2-1

ggplot(data = surveys, 
       mapping = aes(x = weight, y = hindfoot_length)) +
  geom_point(color = "salmon", alpha = 0.5) +
  facet_wrap(~species) +
  labs( x= "Weight (g)",y = NULL, title = "Relationship between weight and hindfoot length across rodent species", subtitle = "Hindfoot Length (mm)") +
  theme(plot.subtitle = element_text(hjust = 0.5))

```

-   Example of **dplyr** pipeline

```{r}
#| label: r-2-2

median_household <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(census_region, study_year) |>
  summarise(median_income = median(mhi_2018, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = study_year, values_from = median_income) |>
  arrange(desc("2018"))

```

-   Example of function formatting

```{r}
#| label: r-2-3



```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example (any context)

```{r}
#| label: r-3-example

```

-   Example (function stops)

```{r}
#| label: r-3-function-stops


```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   At least two numeric variables

```{r}
#| label: dvs-1-num

ggplot(childcare_long, aes(x = study_year, y = weekly_price, color = census_region)) +
  geom_point(alpha = 0.4, size = 1) +
  geom_smooth(method = "loess", se = FALSE, linewidth = 1) +
  facet_wrap(~ age_group) +
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
    x = "Study Year",
    y = NULL,
    color = "California Region") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "right",aspect.ratio = 1,strip.text = element_text(face = "bold"))


```

-   At least one numeric variable and one categorical variable

```{r}
#| label: dvs-2-num-cat

ggplot(data = surveys, 
       mapping = aes(y = species, x = weight)) +
  geom_jitter(color = "grey", alpha = 0.5) +
  geom_boxplot(aes(fill = sex), outliers = FALSE) +
  scale_fill_brewer(palette = 5)
  labs( y= "Species of Rodent",x = "Weight (g)", title = "Relationship between species of rodents and their weight")

```

-   At least two categorical variables

```{r}
#| label: dvs-2-cat

ggplot(childcare_long, aes(x = study_year, y = weekly_price, color = census_region)) +
  geom_point(alpha = 0.4, size = 1) +
  geom_smooth(method = "loess", se = FALSE, linewidth = 1) +
  facet_wrap(~ age_group) +
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
    x = "Study Year",
    y = NULL,
    color = "California Region") +
  theme_minimal(base_size = 12) +
  theme(legend.position = "right",aspect.ratio = 1,strip.text = element_text(face = "bold"))

```

-   Dates (time series plot)

```{r}
#| label: dvs-2-date

#focus on this

```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can modify my plot theme to be more readable

```{r}
#| label: dvs-2-ex-1

```

-   I can modify my colors to be accessible to anyone's eyes

```{r}
#| label: dvs-2-ex-2

```

-   I can modify my plot titles to clearly communicate the data context

```{r}
#| label: dvs-2-ex-3

```

-   I can modify the text in my plot to be more readable

```{r}
#| label: dvs-2-ex-4

#before code chunk, I did not change the font size and I did not separate
ggplot(childcare_long, aes(x = study_year, y = weekly_price, color = census_region)) +
  geom_point(alpha = 0.4, size = 1) +
  geom_smooth(method = "loess", se = FALSE, linewidth = 1) +
  facet_wrap(~ age_group) +
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
    x = "Study Year",
    y = NULL,
    color = "California Region") +
  theme_minimal(base_size = 9) +
  theme(legend.position = "right",aspect.ratio = 1,strip.text = element_text(face = "bold")) 

#here is what my code should have included along with changing the font size to 9 instead of 12

+ scale_x_continuous(breaks = seq(2008, 2018, by = 2), expand = expansion(mult = c(0.05,0.05))) +
  scale_y_continuous(labels = dollar)
```

-   Before and after
-   
-   ![](images/clipboard-1844204121.png)![](images/clipboard-739741966.png)
-   I can reorder my legend to align with the colors in my plot

```{r}
#| label: dvs-2-ex-5

```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors (Example 1)

```{r}
#| label: dvs-3-1-ex-1

```

-   I can use non-standard colors (Example 2)

```{r}
#| label: dvs-3-1-ex-2

```

-   I can use annotations (e.g., `geom_text()`)

```{r}
#| label: dvs-3-2

```

-   I can choose creative geometries (e.g., `geom_segment()`, `geom_ribbon)()`)

```{r}
#| label: dvs-3-3

```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

```{r}
#| label: dvs-4-summarize

```

-   Example using `across()`

```{r}
#| label: dvs-4-across

```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r}
#| label: dvs-5-1

```

-   Example 2

```{r}
#| label: dvs-5-2

```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   I can modify my column names to clearly communicate the data context

```{r}
#| label: dvs-6-ex-1

```

-   I can modify the text in my table to be more readable (e.g., bold face for column headers)

```{r}
#| label: dvs-6-ex-2

```

-   I can arrange my table to have an intuitive ordering

```{r}
#| label: dvs-6-ex-3

```

**DVS-7: I show creativity in my tables.**

-   I can use non-default colors

```{r}
#| label: dvs-7-ex-1

```

-   I can modify the layout of my table to be more readable (e.g., `pivot_longer()` or `pivot_wider()`)

```{r}
#| label: dvs-7-ex-2

```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

```{r}
#| label: pe-1-one-call

```

-   using `across()`

```{r}
#| label: pe-1-across

```

-   using functions from the `map()` family

```{r}
#| label: pe-1-map-1

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1: Function that operates on vectors

```{r}
#| label: pe-2-1

```

-   Example 2: Function that operates on data frames

```{r}
#| label: pe-2-2

```

-   Example 3: Function that operates on vectors *or* data frames

```{r}
#| label: pe-2-3

```

**PE-3:I can use iteration to reduce repetition in my code.**

-   using `across()`

```{r}
#| label: pe-3-across

```

-   using a `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

```{r}
#| label: pe-3-map-1

```

-   using a `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

```{r}
#| label: pe-3-map-2

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

```{r}
#| label: pe-4-1

```

-   I can connect a data wrangling pipeline into a `ggplot()`

```{r}
#| label: pe-4-2

```

## Data Simulation & Statisical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r}
#| label: dsm-1-1

```

-   Example 2

```{r}
#| label: dsm-1-2

```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

```{r}
#| label: dsm-2-1

```

-   Example 2

```{r}
#| label: dsm-2-2

```

-   Example 3

```{r}
#| label: dsm-2-3

```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

I think I am quick to be satisfied if the code runs and gets me moving forward. It's nice to be given the resources on how to own my code but I still think I am in a position where I am insecure with my abilities to even start a line without referring to the cheat sheets or looking at previous work.

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

I think that a lot of my thought process with coding was that efficiency and customization comes last compared to having just the code run. So a big challenge with this course was making space for finding ways that my code could be more professional looking or colorful and not only being satisfied with the code running and getting an answer. I think a lot of lab 5 made me realize like how I should be doing things instead of trying to get a glimpse of an answer by binding rows or searching through the dataframe itself.

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

I have not been supportive of my peers enough to provide evidence of quality feedback. I look forward to changing this response as the final portfolio approaches.

<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

I think this varies because either I am confident in solving the task and can keep up with like a CS major or a more R savvy person or I take too long to think of a line of code to tell the coder and they just take over because class is ending in soon. So I could be faster and give my partner more confidence so that doesn't happen again. At the same time though I've had a partner that was shy and preferred that I took over but then that gives me space to be slow and take my time thinking of code or looking for references.
